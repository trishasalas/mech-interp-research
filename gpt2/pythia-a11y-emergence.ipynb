{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec37119-3bbe-4b3f-949b-7f628a2578a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pythia 160m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ae3178-107d-46d6-b5d8-efb51b14e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils\n",
    "model = HookedTransformer.from_pretrained(\"EleutherAI/pythia-160m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39f3530-c5b8-45ae-9bac-e7e9d17cb7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b0d18abcf84044ba6a63e74c00594e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: A screen reader is\n",
      "Output: A screen reader is a device that allows a user to view a screen\n",
      "\n",
      "Cached 219 different activation points!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A screen reader is\"\n",
    "output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "print(f\"Input: {prompt}\")\n",
    "print(f\"Output: {output}\")\n",
    "\n",
    "# Cache internal states\n",
    "logits, cache = model.run_with_cache(prompt)\n",
    "print(f\"\\nCached {len(cache)} different activation points!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fee1de-c4fb-4a33-9bc2-3e73d7b0345e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f90e54aa48144b6bc737fe7c76f5a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A screen reader is             →  a device that allows a user to view a screen\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7832d95c2440b2b4d411cc7868c1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCAG stands for                →  the International Commission on Geographic Names (ICCG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c37d63b37984547ac7fd030604e931f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A skip link is                 →  a link to a page that is not a link\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d7a36474a941d7bd23606a7e34225b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of alt text is     →  to provide a means for the user to communicate with\n"
     ]
    }
   ],
   "source": [
    "# Test if it knows facts about France\n",
    "test_prompts = [\n",
    "    \"A screen reader is\",\n",
    "    \"WCAG stands for\", \n",
    "    \"A skip link is\",\n",
    "    \"The purpose of alt text is\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "    print(f\"{prompt:30} → {output[len(prompt):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "551b76f5-ed94-4e46-b925-8f8c24af38e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Run this between models\n",
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()\n",
    "print(\"Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc54cd8-e83b-4a1d-989c-e3a9e14cc946",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pythia 410m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e6f01-3ad1-459c-9f06-caa11fb707a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-410m into HookedTransformer\n",
      "Loaded: Pythia 410m\n",
      "Layers: 24\n",
      "Heads: 16\n",
      "Hidden size: 1024\n",
      "Params: 405.3M\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"pythia-410m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab555c-3da6-4a01-8a7b-5234a60d2d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19464498eca34bf186931214e6569868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The capital of France is\n",
      "Output: The capital of France is the\n",
      "\n",
      "Cached 435 different activation points!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A screen reader is\"\n",
    "output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "print(f\"Input: {prompt}\")\n",
    "print(f\"Output: {output}\")\n",
    "\n",
    "# Cache internal states\n",
    "logits, cache = model.run_with_cache(prompt)\n",
    "print(f\"\\nCached {len(cache)} different activation points!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d968d-6276-4f39-ba54-7df08d336504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f714273158af44a3967d682d8eecc733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is       →  the capital of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db155f8e3a274fb5be214637842f048e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of        →  France, and\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e5f73ac2cc4a6aa7c1bf7f0304a64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is a country in         →  which the right\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffb12a5e83d4d87a5d2ac189e39f247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is in         →  Paris, France\n"
     ]
    }
   ],
   "source": [
    "# Test if it knows facts about France\n",
    "test_prompts = [\n",
    "    \"A screen reader is\",\n",
    "    \"WCAG stands for\", \n",
    "    \"A skip link is\",\n",
    "    \"The purpose of alt text is\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "    print(f\"{prompt:30} → {output[len(prompt):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e5c4c-64f6-4f8a-8818-746a45e49d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Run this between models\n",
    "import torch\n",
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()\n",
    "print(\"Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfc0dc-533d-4b8b-a2bb-ef40a03e7be5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pythia 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58f23c-6aa2-42f7-9a7e-5a7193662da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1b into HookedTransformer\n",
      "Loaded: Pythia 1b\n",
      "Layers: 16\n",
      "Heads: 8\n",
      "Hidden size: 2048\n",
      "Params: 1011.7M\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e745fb-417f-429f-86cf-0d494d650195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b2b6e4dc7e4e188cd99d598af7045f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The capital of France is\n",
      "Output: The capital of France is the\n",
      "\n",
      "Cached 291 different activation points!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A screen reader is\"\n",
    "output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "print(f\"Input: {prompt}\")\n",
    "print(f\"Output: {output}\")\n",
    "\n",
    "# Cache internal states\n",
    "logits, cache = model.run_with_cache(prompt)\n",
    "print(f\"\\nCached {len(cache)} different activation points!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cca81-d5b8-4f87-8a9f-2518378ab0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d3028f4fc04e0d9c1531d5343bb5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is       →  a city of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad30af057d0448eda9bb36e13aee9d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of        →  France, and\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502f72d242c443d59d33cc2d938725d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is a country in         →  which the French\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1352862dc446dba7eda1e64c556d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is in         →  the midst of\n"
     ]
    }
   ],
   "source": [
    "# Test if it knows facts about France\n",
    "test_prompts = [\n",
    "    \"A screen reader is\",\n",
    "    \"WCAG stands for\", \n",
    "    \"A skip link is\",\n",
    "    \"The purpose of alt text is\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "    print(f\"{prompt:30} → {output[len(prompt):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23c7c8-4fac-4f48-8608-1931a8652928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Run this between models\n",
    "import torch\n",
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()\n",
    "print(\"Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b71f5b-30f3-4798-b14e-1ecaaf1a8601",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pythia 2.8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907dc56-5998-4b17-8213-9e92ad17fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68553d6a60249bca8cf88686a8e09dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3116f0b048c341999fb9caf62056ad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78230cce0d3d4887aaa4562d85c641e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21293d74b774a7a9fd37fa76c0c9a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c36ad3b102441bbf4af6550e72eba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-2.8b into HookedTransformer\n",
      "Loaded: Pythia 2.8b\n",
      "Layers: 32\n",
      "Heads: 32\n",
      "Hidden size: 2560\n",
      "Params: 2774.9M\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930720d-1946-4ea0-9288-71ec033be4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0650dd62af843c4816356a16fc67d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The capital of France is\n",
      "Output: The capital of France is Paris\n",
      "\n",
      "Cached 579 different activation points!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A screen reader is\"\n",
    "output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "print(f\"Input: {prompt}\")\n",
    "print(f\"Output: {output}\")\n",
    "\n",
    "# Cache internal states\n",
    "logits, cache = model.run_with_cache(prompt)\n",
    "print(f\"\\nCached {len(cache)} different activation points!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b4ab3-462e-4120-9fd5-05d146d15a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c44d8507574d969ef009a18f0bccfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is       →  a city of\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31e8fd107554cf7ad2bdb26abee890c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of        →  France and the\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ede5e289be94c2b8c88290ea3dd2d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is a country in         →  Europe, located\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39fdd4bb35f4737b2d407397a6afa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is in         →  the news again\n"
     ]
    }
   ],
   "source": [
    "# Test if it knows facts about France\n",
    "test_prompts = [\n",
    "    \"A screen reader is\",\n",
    "    \"WCAG stands for\", \n",
    "    \"A skip link is\",\n",
    "    \"The purpose of alt text is\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    output = model.generate(prompt, max_new_tokens=10, temperature=0)\n",
    "    print(f\"{prompt:30} → {output[len(prompt):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e445e-3ffa-4129-83e2-136498b96412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Run this between models\n",
    "import torch\n",
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.mps.empty_cache()\n",
    "print(\"Memory cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566735b-2056-4272-b6f3-85d8e9ba71bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
